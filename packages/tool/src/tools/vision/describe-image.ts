/**
 * Describe Image Tool
 *
 * High-level tool that describes an image using provider's vision capability.
 * This tool signals to the LLM to analyze the image content.
 *
 * @module @vellum/tool/vision
 * @see REQ-VIS-006 - Describe image tool
 */

import { resolve } from "node:path";
import { createVisionService, defineTool, fail, ok } from "@vellum/core";
import { z } from "zod";

// =============================================================================
// Schemas
// =============================================================================

/**
 * Parameters schema for describe_image tool
 */
export const describeImageParamsSchema = z.object({
  /** Path to the image file to describe */
  path: z.string().describe("Path to the image file to describe"),
  /** Optional prompt/question about the image */
  prompt: z
    .string()
    .optional()
    .describe("Optional prompt or question about the image (e.g., 'What text is visible?')"),
  /** Detail level for analysis */
  detailLevel: z
    .enum(["low", "high", "auto"])
    .optional()
    .default("auto")
    .describe("Level of detail for image analysis"),
});

/** Inferred type for describe_image parameters */
export type DescribeImageParams = z.infer<typeof describeImageParamsSchema>;

// =============================================================================
// Output Types
// =============================================================================

/**
 * Output structure for describe_image tool
 *
 * This tool returns the image data for the LLM to analyze.
 * The actual description is generated by the LLM based on the image.
 */
export interface DescribeImageOutput {
  /** Base64-encoded image data */
  imageData: string;
  /** MIME type of the image */
  mimeType: string;
  /** Original prompt/question if provided */
  prompt?: string;
  /** Image metadata */
  metadata: {
    /** File path */
    path: string;
    /** Width in pixels */
    width?: number;
    /** Height in pixels */
    height?: number;
    /** File size in bytes */
    fileSizeBytes: number;
  };
  /** Instructions for the LLM */
  analysisRequest: string;
}

// =============================================================================
// Tool Implementation
// =============================================================================

/**
 * Describe image tool implementation
 *
 * Loads an image and prepares it for vision analysis by the LLM.
 * The tool returns the image data along with analysis instructions.
 *
 * This is a high-level tool that leverages the provider's vision capability
 * to understand and describe image contents.
 *
 * @example
 * ```typescript
 * // Describe an image
 * const result = await describeImageTool.execute({
 *   path: "diagram.png"
 * }, ctx);
 *
 * // Ask a specific question about the image
 * const result = await describeImageTool.execute({
 *   path: "screenshot.png",
 *   prompt: "What errors are shown in this screenshot?"
 * }, ctx);
 * ```
 */
export const describeImageTool = defineTool({
  name: "describe_image",
  description:
    "Analyze and describe an image using vision capabilities. Load an image file and request analysis from the LLM. Can include a specific prompt or question about the image content.",
  parameters: describeImageParamsSchema,
  kind: "read",
  category: "vision",

  async execute(input, ctx) {
    // Check for cancellation
    if (ctx.abortSignal.aborted) {
      return fail("Operation was cancelled");
    }

    // Resolve path relative to working directory
    const resolvedPath = resolve(ctx.workingDir, input.path);

    // Security: ensure path is within working directory
    if (!resolvedPath.startsWith(ctx.workingDir)) {
      return fail("Path traversal not allowed - path must be within working directory");
    }

    const visionService = createVisionService();

    try {
      // Validate the image first
      const validation = await visionService.validateFile(resolvedPath);
      if (!validation.valid) {
        return fail(validation.error ?? "Image validation failed");
      }

      // Load the image
      const loaded = await visionService.loadImage({
        type: "file",
        path: resolvedPath,
      });

      // Build analysis request
      let analysisRequest: string;
      if (input.prompt) {
        analysisRequest = `Please analyze the following image and answer this question: ${input.prompt}`;
      } else {
        analysisRequest =
          "Please analyze and describe the contents of this image in detail. Include any text, objects, people, or notable elements visible.";
      }

      if (input.detailLevel === "low") {
        analysisRequest += " Provide a brief summary.";
      } else if (input.detailLevel === "high") {
        analysisRequest +=
          " Provide comprehensive details including layout, colors, text content, and any relevant context.";
      }

      return ok<DescribeImageOutput>({
        imageData: loaded.data,
        mimeType: loaded.mimeType,
        prompt: input.prompt,
        metadata: {
          path: resolvedPath,
          width: loaded.metadata.originalDimensions?.width,
          height: loaded.metadata.originalDimensions?.height,
          fileSizeBytes: loaded.metadata.fileSizeBytes ?? 0,
        },
        analysisRequest,
      });
    } catch (error) {
      const message = error instanceof Error ? error.message : "Failed to load image";
      return fail(message);
    }
  },
});
